{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "error",
     "timestamp": 1743620315360,
     "user": {
      "displayName": "ryan punamiya",
      "userId": "01065383722440132219"
     },
     "user_tz": 240
    },
    "id": "VrX4VTl5pYNq",
    "outputId": "c09c5b06-4ba3-4dca-a026-1db92e4d0208",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Imports**\n",
    "# diffusion policy import\n",
    "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import collections\n",
    "import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# env import\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import pymunk\n",
    "import pymunk.pygame_util\n",
    "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
    "from pymunk.vec2d import Vec2d\n",
    "import shapely.geometry as sg\n",
    "import cv2\n",
    "import skimage.transform as st\n",
    "from skvideo.io import vwrite\n",
    "from IPython.display import Video\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "form",
    "id": "L5E-nR6ornyg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Environment**\n",
    "#@markdown Defines a PyMunk-based Push-T environment `PushTEnv`.\n",
    "#@markdown And it's subclass `PushTImageEnv`.\n",
    "#@markdown\n",
    "#@markdown **Goal**: push the gray T-block into the green area.\n",
    "#@markdown\n",
    "#@markdown Adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/)\n",
    "\n",
    "\n",
    "positive_y_is_up: bool = False\n",
    "\"\"\"Make increasing values of y point upwards.\n",
    "\n",
    "When True::\n",
    "\n",
    "    y\n",
    "    ^\n",
    "    |      . (3, 3)\n",
    "    |\n",
    "    |   . (2, 2)\n",
    "    |\n",
    "    +------ > x\n",
    "\n",
    "When False::\n",
    "\n",
    "    +------ > x\n",
    "    |\n",
    "    |   . (2, 2)\n",
    "    |\n",
    "    |      . (3, 3)\n",
    "    v\n",
    "    y\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
    "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
    "    local coordinates.\n",
    "\n",
    "    Note that in case positive_y_is_up is False, this function wont actually do\n",
    "    anything except converting the point to integers.\n",
    "    \"\"\"\n",
    "    if positive_y_is_up:\n",
    "        return round(p[0]), surface.get_height() - round(p[1])\n",
    "    else:\n",
    "        return round(p[0]), round(p[1])\n",
    "\n",
    "\n",
    "def light_color(color: SpaceDebugColor):\n",
    "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
    "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
    "    return color\n",
    "\n",
    "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
    "    def __init__(self, surface: pygame.Surface) -> None:\n",
    "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
    "\n",
    "        Typical usage::\n",
    "\n",
    "        >>> import pymunk\n",
    "        >>> surface = pygame.Surface((10,10))\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        You can control the color of a shape by setting shape.color to the color\n",
    "        you want it drawn in::\n",
    "\n",
    "        >>> c = pymunk.Circle(None, 10)\n",
    "        >>> c.color = pygame.Color(\"pink\")\n",
    "\n",
    "        See pygame_util.demo.py for a full example\n",
    "\n",
    "        Since pygame uses a coordiante system where y points down (in contrast\n",
    "        to many other cases), you either have to make the physics simulation\n",
    "        with Pymunk also behave in that way, or flip everything when you draw.\n",
    "\n",
    "        The easiest is probably to just make the simulation behave the same\n",
    "        way as Pygame does. In that way all coordinates used are in the same\n",
    "        orientation and easy to reason about::\n",
    "\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> space.gravity = (0, -1000)\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        To flip the drawing its possible to set the module property\n",
    "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
    "        the simulation upside down before drawing::\n",
    "\n",
    "        >>> positive_y_is_up = True\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0)\n",
    "        >>> # Body will be position in bottom left corner\n",
    "\n",
    "        :Parameters:\n",
    "                surface : pygame.Surface\n",
    "                    Surface that the objects will be drawn on\n",
    "        \"\"\"\n",
    "        self.surface = surface\n",
    "        super(DrawOptions, self).__init__()\n",
    "\n",
    "    def draw_circle(\n",
    "        self,\n",
    "        pos: Vec2d,\n",
    "        angle: float,\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "\n",
    "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
    "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
    "\n",
    "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
    "        p2 = to_pygame(circle_edge, self.surface)\n",
    "        line_r = 2 if radius > 20 else 1\n",
    "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
    "\n",
    "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
    "\n",
    "    def draw_fat_segment(\n",
    "        self,\n",
    "        a: Tuple[float, float],\n",
    "        b: Tuple[float, float],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        r = round(max(1, radius * 2))\n",
    "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
    "        if r > 2:\n",
    "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
    "            if orthog[0] == 0 and orthog[1] == 0:\n",
    "                return\n",
    "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
    "            orthog[0] = round(orthog[0] * scale)\n",
    "            orthog[1] = round(orthog[1] * scale)\n",
    "            points = [\n",
    "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
    "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
    "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
    "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
    "            ]\n",
    "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p1[0]), round(p1[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p2[0]), round(p2[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "\n",
    "    def draw_polygon(\n",
    "        self,\n",
    "        verts: Sequence[Tuple[float, float]],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        ps = [to_pygame(v, self.surface) for v in verts]\n",
    "        ps += [ps[0]]\n",
    "\n",
    "        radius = 2\n",
    "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
    "\n",
    "        if radius > 0:\n",
    "            for i in range(len(verts)):\n",
    "                a = verts[i]\n",
    "                b = verts[(i + 1) % len(verts)]\n",
    "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
    "\n",
    "    def draw_dot(\n",
    "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
    "\n",
    "def pymunk_to_shapely(body, shapes):\n",
    "    geoms = list()\n",
    "    for shape in shapes:\n",
    "        if isinstance(shape, pymunk.shapes.Poly):\n",
    "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
    "            verts += [verts[0]]\n",
    "            geoms.append(sg.Polygon(verts))\n",
    "        else:\n",
    "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
    "    geom = sg.MultiPolygon(geoms)\n",
    "    return geom\n",
    "\n",
    "# env\n",
    "class PushTEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "    reward_range = (0., 1.)\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None, damping=None,\n",
    "            render_action=True,\n",
    "            render_size=96,\n",
    "            reset_to_state=None\n",
    "        ):\n",
    "        self._seed = None\n",
    "        self.seed()\n",
    "        self.window_size = ws = 512  # The size of the PyGame window\n",
    "        self.render_size = render_size\n",
    "        self.sim_hz = 100\n",
    "        # Local controller params.\n",
    "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
    "        self.control_hz = self.metadata['video.frames_per_second']\n",
    "        # legcay set_state for data compatiblity\n",
    "        self.legacy = legacy\n",
    "\n",
    "        # agent_pos, block_pos, block_angle\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
    "            shape=(5,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # positional goal for agent\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws], dtype=np.float64),\n",
    "            shape=(2,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        self.block_cog = block_cog\n",
    "        self.damping = damping\n",
    "        self.render_action = render_action\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self.screen = None\n",
    "\n",
    "        self.space = None\n",
    "        self.teleop = None\n",
    "        self.render_buffer = None\n",
    "        self.latest_action = None\n",
    "        self.reset_to_state = reset_to_state\n",
    "\n",
    "    def reset(self):\n",
    "        seed = self._seed\n",
    "        self._setup()\n",
    "        if self.block_cog is not None:\n",
    "            self.block.center_of_gravity = self.block_cog\n",
    "        if self.damping is not None:\n",
    "            self.space.damping = self.damping\n",
    "\n",
    "        # use legacy RandomState for compatiblity\n",
    "        state = self.reset_to_state\n",
    "        if state is None:\n",
    "            rs = np.random.RandomState(seed=seed)\n",
    "            state = np.array([\n",
    "                rs.randint(50, 450), rs.randint(50, 450),\n",
    "                rs.randint(100, 400), rs.randint(100, 400),\n",
    "                rs.randn() * 2 * np.pi - np.pi\n",
    "                ])\n",
    "        self._set_state(state)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        dt = 1.0 / self.sim_hz\n",
    "        self.n_contact_points = 0\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        if action is not None:\n",
    "            self.latest_action = action\n",
    "            for i in range(n_steps):\n",
    "                # Step PD control.\n",
    "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
    "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
    "                self.agent.velocity += acceleration * dt\n",
    "\n",
    "                # Step physics.\n",
    "                self.space.step(dt)\n",
    "\n",
    "        # compute reward\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
    "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
    "\n",
    "        intersection_area = goal_geom.intersection(block_geom).area\n",
    "        goal_area = goal_geom.area\n",
    "        coverage = intersection_area / goal_area\n",
    "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
    "        done = coverage > self.success_threshold\n",
    "        terminated = done\n",
    "        truncated = done\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode):\n",
    "        return self._render_frame(mode)\n",
    "\n",
    "    def teleop_agent(self):\n",
    "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
    "        def act(obs):\n",
    "            act = None\n",
    "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
    "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
    "                self.teleop = True\n",
    "                act = mouse_position\n",
    "            return act\n",
    "        return TeleopAgent(act)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = np.array(\n",
    "            tuple(self.agent.position) \\\n",
    "            + tuple(self.block.position) \\\n",
    "            + (self.block.angle % (2 * np.pi),))\n",
    "        return obs\n",
    "\n",
    "    def _get_goal_pose_body(self, pose):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        # preserving the legacy assignment order for compatibility\n",
    "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
    "        body.position = pose[:2].tolist()\n",
    "        body.angle = pose[2]\n",
    "        return body\n",
    "\n",
    "    def _get_info(self):\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
    "        info = {\n",
    "            'pos_agent': np.array(self.agent.position),\n",
    "            'vel_agent': np.array(self.agent.velocity),\n",
    "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
    "            'goal_pose': self.goal_pose,\n",
    "            'n_contacts': n_contact_points_per_step}\n",
    "        return info\n",
    "\n",
    "    def _render_frame(self, mode):\n",
    "\n",
    "        if self.window is None and mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        self.screen = canvas\n",
    "\n",
    "        draw_options = DrawOptions(canvas)\n",
    "\n",
    "        # Draw goal pose.\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        for shape in self.block.shapes:\n",
    "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
    "            goal_points += [goal_points[0]]\n",
    "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
    "\n",
    "        # Draw agent and block.\n",
    "        self.space.debug_draw(draw_options)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # the clock is aleady ticked during in step for \"human\"\n",
    "\n",
    "\n",
    "        img = np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
    "        if self.render_action:\n",
    "            if self.render_action and (self.latest_action is not None):\n",
    "                action = np.array(self.latest_action)\n",
    "                coord = (action / 512 * 96).astype(np.int32)\n",
    "                marker_size = int(8/96*self.render_size)\n",
    "                thickness = int(1/96*self.render_size)\n",
    "                cv2.drawMarker(img, coord,\n",
    "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                    markerSize=marker_size, thickness=thickness)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0,25536)\n",
    "        self._seed = seed\n",
    "        self.np_random = np.random.default_rng(seed)\n",
    "\n",
    "    def _handle_collision(self, arbiter, space, data):\n",
    "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
    "\n",
    "    def _set_state(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = state.tolist()\n",
    "        pos_agent = state[:2]\n",
    "        pos_block = state[2:4]\n",
    "        rot_block = state[4]\n",
    "        self.agent.position = pos_agent\n",
    "        # setting angle rotates with respect to center of mass\n",
    "        # therefore will modify the geometric position\n",
    "        # if not the same as CoM\n",
    "        # therefore should be modified first.\n",
    "        if self.legacy:\n",
    "            # for compatiblity with legacy data\n",
    "            self.block.position = pos_block\n",
    "            self.block.angle = rot_block\n",
    "        else:\n",
    "            self.block.angle = rot_block\n",
    "            self.block.position = pos_block\n",
    "\n",
    "        # Run physics to take effect\n",
    "        self.space.step(1.0 / self.sim_hz)\n",
    "\n",
    "    def _set_state_local(self, state_local):\n",
    "        agent_pos_local = state_local[:2]\n",
    "        block_pose_local = state_local[2:]\n",
    "        tf_img_obj = st.AffineTransform(\n",
    "            translation=self.goal_pose[:2],\n",
    "            rotation=self.goal_pose[2])\n",
    "        tf_obj_new = st.AffineTransform(\n",
    "            translation=block_pose_local[:2],\n",
    "            rotation=block_pose_local[2]\n",
    "        )\n",
    "        tf_img_new = st.AffineTransform(\n",
    "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
    "        )\n",
    "        agent_pos_new = tf_img_new(agent_pos_local)\n",
    "        new_state = np.array(\n",
    "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
    "                + [tf_img_new.rotation])\n",
    "        self._set_state(new_state)\n",
    "        return new_state\n",
    "\n",
    "    def _setup(self):\n",
    "        self.space = pymunk.Space()\n",
    "        self.space.gravity = 0, 0\n",
    "        self.space.damping = 0\n",
    "        self.teleop = False\n",
    "        self.render_buffer = list()\n",
    "\n",
    "        # Add walls.\n",
    "        walls = [\n",
    "            self._add_segment((5, 506), (5, 5), 2),\n",
    "            self._add_segment((5, 5), (506, 5), 2),\n",
    "            self._add_segment((506, 5), (506, 506), 2),\n",
    "            self._add_segment((5, 506), (506, 506), 2)\n",
    "        ]\n",
    "        self.space.add(*walls)\n",
    "\n",
    "        # Add agent, block, and goal zone.\n",
    "        self.agent = self.add_circle((256, 400), 15)\n",
    "        self.block = self.add_tee((256, 300), 0)\n",
    "        self.goal_color = pygame.Color('LightGreen')\n",
    "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
    "        \n",
    "    \n",
    "\n",
    "        # Add collision handeling\n",
    "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
    "        self.collision_handeler.post_solve = self._handle_collision\n",
    "        self.n_contact_points = 0\n",
    "\n",
    "        self.max_score = 50 * 100\n",
    "        self.success_threshold = 0.95    # 95% coverage.\n",
    "    \n",
    "    def add_triangle(self, position, size=30, color=\"LightCoral\"):\n",
    "        h = size * np.sqrt(3) / 2  # height of equilateral triangle\n",
    "        vertices = [\n",
    "            (0, -2*h/3),            # bottom point\n",
    "            (-size/2, h/3),         # top-left\n",
    "            (size/2, h/3)           # top-right\n",
    "        ]\n",
    "        \n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 0.8 # slight diff friction\n",
    "        \n",
    "        shape = pymunk.Poly(body, vertices)\n",
    "        shape.color = pygame.Color(color)\n",
    "        \n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "    \n",
    "    def _add_segment(self, a, b, radius):\n",
    "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
    "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
    "        return shape\n",
    "\n",
    "    def add_circle(self, position, radius):\n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 1\n",
    "        shape = pymunk.Circle(body, radius)\n",
    "        shape.color = pygame.Color('RoyalBlue')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_box(self, position, height, width):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        body.position = position\n",
    "        shape = pymunk.Poly.create_box(body, (height, width))\n",
    "        shape.color = pygame.Color('LightSlateGray')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
    "        mass = 1\n",
    "        length = 4\n",
    "        vertices1 = [(-length*scale/2, scale),\n",
    "                                 ( length*scale/2, scale),\n",
    "                                 ( length*scale/2, 0),\n",
    "                                 (-length*scale/2, 0)]\n",
    "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        vertices2 = [(-scale/2, scale),\n",
    "                                 (-scale/2, length*scale),\n",
    "                                 ( scale/2, length*scale),\n",
    "                                 ( scale/2, scale)]\n",
    "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
    "        shape1 = pymunk.Poly(body, vertices1)\n",
    "        shape2 = pymunk.Poly(body, vertices2)\n",
    "        shape1.color = pygame.Color(color)\n",
    "        shape2.color = pygame.Color(color)\n",
    "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
    "        body.position = position\n",
    "        body.angle = angle\n",
    "        body.friction = 1\n",
    "        self.space.add(body, shape1, shape2)\n",
    "        return body\n",
    "\n",
    "\n",
    "class PushTImageEnv(PushTEnv):\n",
    "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None,\n",
    "            damping=None,\n",
    "            render_size=96):\n",
    "        super().__init__(\n",
    "            legacy=legacy,\n",
    "            block_cog=block_cog,\n",
    "            damping=damping,\n",
    "            render_size=render_size,\n",
    "            render_action=False)\n",
    "        ws = self.window_size\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'image': spaces.Box(\n",
    "                low=0,\n",
    "                high=1,\n",
    "                shape=(3,render_size,render_size),\n",
    "                dtype=np.float32\n",
    "            ),\n",
    "            'agent_pos': spaces.Box(\n",
    "                low=0,\n",
    "                high=ws,\n",
    "                shape=(2,),\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        })\n",
    "        self.render_cache = None\n",
    "\n",
    "    def _get_obs(self):\n",
    "        img = super()._render_frame(mode='rgb_array')\n",
    "\n",
    "        agent_pos = np.array(self.agent.position)\n",
    "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
    "        obs = {\n",
    "            'image': img_obs,\n",
    "            'agent_pos': agent_pos\n",
    "        }\n",
    "\n",
    "        # draw action\n",
    "        if self.latest_action is not None:\n",
    "            action = np.array(self.latest_action)\n",
    "            coord = (action / 512 * 96).astype(np.int32)\n",
    "            marker_size = int(8/96*self.render_size)\n",
    "            thickness = int(1/96*self.render_size)\n",
    "            cv2.drawMarker(img, coord,\n",
    "                color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                markerSize=marker_size, thickness=thickness)\n",
    "        self.render_cache = img\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode):\n",
    "        assert mode == 'rgb_array'\n",
    "\n",
    "        if self.render_cache is None:\n",
    "            self._get_obs()\n",
    "\n",
    "        return self.render_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PushTEnv2(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "    reward_range = (0., 1.)\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None, damping=None,\n",
    "            render_action=True,\n",
    "            render_size=96,\n",
    "            reset_to_state=None\n",
    "        ):\n",
    "        self._seed = None\n",
    "        self.seed()\n",
    "        self.window_size = ws = 512  # The size of the PyGame window\n",
    "        self.render_size = render_size\n",
    "        self.sim_hz = 100\n",
    "        # Local controller params.\n",
    "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
    "        self.control_hz = self.metadata['video.frames_per_second']\n",
    "        # legcay set_state for data compatiblity\n",
    "        self.legacy = legacy\n",
    "\n",
    "        # agent_pos, block_pos, block_angle\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
    "            shape=(5,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # positional goal for agent\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws], dtype=np.float64),\n",
    "            shape=(2,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        self.block_cog = block_cog\n",
    "        self.damping = damping\n",
    "        self.render_action = render_action\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self.screen = None\n",
    "\n",
    "        self.space = None\n",
    "        self.teleop = None\n",
    "        self.render_buffer = None\n",
    "        self.latest_action = None\n",
    "        self.reset_to_state = reset_to_state\n",
    "\n",
    "    def reset(self):\n",
    "        seed = self._seed\n",
    "        self._setup()\n",
    "        if self.block_cog is not None:\n",
    "            self.block.center_of_gravity = self.block_cog\n",
    "        if self.damping is not None:\n",
    "            self.space.damping = self.damping\n",
    "\n",
    "        # use legacy RandomState for compatiblity\n",
    "        state = self.reset_to_state\n",
    "        if state is None:\n",
    "            rs = np.random.RandomState(seed=seed)\n",
    "            state = np.array([\n",
    "                rs.randint(50, 450), rs.randint(50, 450),\n",
    "                rs.randint(100, 400), rs.randint(100, 400),\n",
    "                rs.randn() * 2 * np.pi - np.pi\n",
    "                ])\n",
    "        self._set_state(state)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        dt = 1.0 / self.sim_hz\n",
    "        self.n_contact_points = 0\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        if action is not None:\n",
    "            self.latest_action = action\n",
    "            for i in range(n_steps):\n",
    "                # Step PD control.\n",
    "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
    "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
    "                self.agent.velocity += acceleration * dt\n",
    "\n",
    "                # Step physics.\n",
    "                self.space.step(dt)\n",
    "\n",
    "        # compute reward\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
    "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
    "\n",
    "        intersection_area = goal_geom.intersection(block_geom).area\n",
    "        goal_area = goal_geom.area\n",
    "        coverage = intersection_area / goal_area\n",
    "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
    "        done = coverage > self.success_threshold\n",
    "        terminated = done\n",
    "        truncated = done\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode):\n",
    "        return self._render_frame(mode)\n",
    "\n",
    "    def teleop_agent(self):\n",
    "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
    "        def act(obs):\n",
    "            act = None\n",
    "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
    "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
    "                self.teleop = True\n",
    "                act = mouse_position\n",
    "            return act\n",
    "        return TeleopAgent(act)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = np.array(\n",
    "            tuple(self.agent.position) \\\n",
    "            + tuple(self.block.position) \\\n",
    "            + (self.block.angle % (2 * np.pi),))\n",
    "        return obs\n",
    "\n",
    "    def _get_goal_pose_body(self, pose):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        # preserving the legacy assignment order for compatibility\n",
    "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
    "        body.position = pose[:2].tolist()\n",
    "        body.angle = pose[2]\n",
    "        return body\n",
    "\n",
    "    def _get_info(self):\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
    "        info = {\n",
    "            'pos_agent': np.array(self.agent.position),\n",
    "            'vel_agent': np.array(self.agent.velocity),\n",
    "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
    "            'goal_pose': self.goal_pose,\n",
    "            'n_contacts': n_contact_points_per_step}\n",
    "        return info\n",
    "\n",
    "    def _render_frame(self, mode):\n",
    "\n",
    "        if self.window is None and mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((186, 85, 211))\n",
    "        self.screen = canvas\n",
    "\n",
    "        draw_options = DrawOptions(canvas)\n",
    "\n",
    "        # Draw goal pose.\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        for shape in self.block.shapes:\n",
    "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
    "            goal_points += [goal_points[0]]\n",
    "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
    "\n",
    "        # Draw agent and block.\n",
    "        self.space.debug_draw(draw_options)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # the clock is aleady ticked during in step for \"human\"\n",
    "\n",
    "\n",
    "        img = np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
    "        if self.render_action:\n",
    "            if self.render_action and (self.latest_action is not None):\n",
    "                action = np.array(self.latest_action)\n",
    "                coord = (action / 512 * 96).astype(np.int32)\n",
    "                marker_size = int(8/96*self.render_size)\n",
    "                thickness = int(1/96*self.render_size)\n",
    "                cv2.drawMarker(img, coord,\n",
    "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                    markerSize=marker_size, thickness=thickness)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0,25536)\n",
    "        self._seed = seed\n",
    "        self.np_random = np.random.default_rng(seed)\n",
    "\n",
    "    def _handle_collision(self, arbiter, space, data):\n",
    "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
    "\n",
    "    def _set_state(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = state.tolist()\n",
    "        pos_agent = state[:2]\n",
    "        pos_block = state[2:4]\n",
    "        rot_block = state[4]\n",
    "        \n",
    "        pos_agent = self.rotate90_clockwise(state[:2])\n",
    "        pos_block = self.rotate90_clockwise(state[2:4])\n",
    "        rot_block = state[4] - np.pi / 2  # subtract 90 degrees in radians\n",
    "\n",
    "        self.agent.position = pos_agent\n",
    "        # setting angle rotates with respect to center of mass\n",
    "        # therefore will modify the geometric position\n",
    "        # if not the same as CoM\n",
    "        # therefore should be modified first.\n",
    "        if self.legacy:\n",
    "            # for compatiblity with legacy data\n",
    "            self.block.position = pos_block\n",
    "            self.block.angle = rot_block\n",
    "        else:\n",
    "            self.block.angle = rot_block\n",
    "            self.block.position = pos_block\n",
    "\n",
    "        # Run physics to take effect\n",
    "        self.space.step(1.0 / self.sim_hz)\n",
    "\n",
    "    def _set_state_local(self, state_local):\n",
    "        agent_pos_local = state_local[:2]\n",
    "        block_pose_local = state_local[2:]\n",
    "        tf_img_obj = st.AffineTransform(\n",
    "            translation=self.goal_pose[:2],\n",
    "            rotation=self.goal_pose[2])\n",
    "        tf_obj_new = st.AffineTransform(\n",
    "            translation=block_pose_local[:2],\n",
    "            rotation=block_pose_local[2]\n",
    "        )\n",
    "        tf_img_new = st.AffineTransform(\n",
    "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
    "        )\n",
    "        agent_pos_new = tf_img_new(agent_pos_local)\n",
    "        new_state = np.array(\n",
    "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
    "                + [tf_img_new.rotation])\n",
    "        self._set_state(new_state)\n",
    "        return new_state\n",
    "\n",
    "    def _setup(self):\n",
    "        self.space = pymunk.Space()\n",
    "        self.space.gravity = 0, 0\n",
    "        self.space.damping = 0\n",
    "        self.teleop = False\n",
    "        self.render_buffer = list()\n",
    "\n",
    "        # Add walls.\n",
    "        walls = [\n",
    "            self._add_segment((5, 506), (5, 5), 2),\n",
    "            self._add_segment((5, 5), (506, 5), 2),\n",
    "            self._add_segment((506, 5), (506, 506), 2),\n",
    "            self._add_segment((5, 506), (506, 506), 2)\n",
    "        ]\n",
    "        self.space.add(*walls)\n",
    "\n",
    "        # Add agent, block, and goal zone.\n",
    "        self.agent = self.add_triangle((256, 400), 40)\n",
    "        self.block = self.add_tee((256, 300), 0)\n",
    "        self.goal_color = pygame.Color('LightGreen')\n",
    "        goal_pose = np.array([256, 256, np.pi/4])\n",
    "\n",
    "        # Rotate position\n",
    "        goal_pose[:2] = self.rotate90_clockwise(goal_pose[:2])\n",
    "\n",
    "        # Rotate orientation\n",
    "        goal_pose[2] -= np.pi / 2\n",
    "\n",
    "        self.goal_pose = goal_pose\n",
    "\n",
    "        # Add collision handeling\n",
    "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
    "        self.collision_handeler.post_solve = self._handle_collision\n",
    "        self.n_contact_points = 0\n",
    "\n",
    "        self.max_score = 50 * 100\n",
    "        self.success_threshold = 0.95    # 95% coverage.\n",
    "    \n",
    "    def add_triangle(self, position, size=30, color=\"LightCoral\"):\n",
    "        h = size * np.sqrt(3) / 2  # height of equilateral triangle\n",
    "        vertices = [\n",
    "            (0, -2*h/3),            # bottom point\n",
    "            (-size/2, h/3),         # top-left\n",
    "            (size/2, h/3)           # top-right\n",
    "        ]\n",
    "        \n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 0.8 # slight diff friction\n",
    "        \n",
    "        shape = pymunk.Poly(body, vertices)\n",
    "        shape.color = pygame.Color(color)\n",
    "        \n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "    \n",
    "    def _add_segment(self, a, b, radius):\n",
    "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
    "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
    "        return shape\n",
    "\n",
    "    def add_circle(self, position, radius):\n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 1\n",
    "        shape = pymunk.Circle(body, radius)\n",
    "        shape.color = pygame.Color('RoyalBlue')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_box(self, position, height, width):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        body.position = position\n",
    "        shape = pymunk.Poly.create_box(body, (height, width))\n",
    "        shape.color = pygame.Color('LightSlateGray')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
    "        mass = 1\n",
    "        length = 4\n",
    "        vertices1 = [(-length*scale/2, scale),\n",
    "                                 ( length*scale/2, scale),\n",
    "                                 ( length*scale/2, 0),\n",
    "                                 (-length*scale/2, 0)]\n",
    "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        vertices2 = [(-scale/2, scale),\n",
    "                                 (-scale/2, length*scale),\n",
    "                                 ( scale/2, length*scale),\n",
    "                                 ( scale/2, scale)]\n",
    "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
    "        shape1 = pymunk.Poly(body, vertices1)\n",
    "        shape2 = pymunk.Poly(body, vertices2)\n",
    "        shape1.color = pygame.Color(color)\n",
    "        shape2.color = pygame.Color(color)\n",
    "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
    "        body.position = position\n",
    "        body.angle = angle\n",
    "        body.friction = 1\n",
    "        self.space.add(body, shape1, shape2)\n",
    "        return body\n",
    "\n",
    "    def rotate90_clockwise(self, pos, center=(256, 256)):\n",
    "        x0, y0 = pos[0] - center[0], pos[1] - center[1]\n",
    "        x1, y1 = y0, -x0\n",
    "        return [x1 + center[0], y1 + center[1]]\n",
    "    \n",
    "    def rotate_keypoints(self, kps, center=(256, 256)):\n",
    "        kps_rot = kps.copy()\n",
    "        for i in range(len(kps)):\n",
    "            x, y = kps[i]\n",
    "            x0, y0 = x - center[0], y - center[1]\n",
    "            x1, y1 = y0, -x0\n",
    "            kps_rot[i] = [x1 + center[0], y1 + center[1]]\n",
    "        return kps_rot\n",
    "    \n",
    "\n",
    "class PushTImageEnv2(PushTEnv2):\n",
    "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None,\n",
    "            damping=None,\n",
    "            render_size=96):\n",
    "        super().__init__(\n",
    "            legacy=legacy,\n",
    "            block_cog=block_cog,\n",
    "            damping=damping,\n",
    "            render_size=render_size,\n",
    "            render_action=False)\n",
    "        ws = self.window_size\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'image': spaces.Box(\n",
    "                low=0,\n",
    "                high=1,\n",
    "                shape=(3,render_size,render_size),\n",
    "                dtype=np.float32\n",
    "            ),\n",
    "            'agent_pos': spaces.Box(\n",
    "                low=0,\n",
    "                high=ws,\n",
    "                shape=(2,),\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        })\n",
    "        self.render_cache = None\n",
    "\n",
    "    def _get_obs(self):\n",
    "        img = super()._render_frame(mode='rgb_array')\n",
    "\n",
    "        agent_pos = np.array(self.agent.position)\n",
    "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
    "        obs = {\n",
    "            'image': img_obs,\n",
    "            'agent_pos': agent_pos\n",
    "        }\n",
    "\n",
    "        # draw action\n",
    "        if self.latest_action is not None:\n",
    "            action = np.array(self.latest_action)\n",
    "            coord = (action / 512 * 96).astype(np.int32)\n",
    "            marker_size = int(8/96*self.render_size)\n",
    "            thickness = int(1/96*self.render_size)\n",
    "            cv2.drawMarker(img, coord,\n",
    "                color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                markerSize=marker_size, thickness=thickness)\n",
    "        self.render_cache = img\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode):\n",
    "        assert mode == 'rgb_array'\n",
    "\n",
    "        if self.render_cache is None:\n",
    "            self._get_obs()\n",
    "\n",
    "        return self.render_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "OknH8Qfqrtc9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs['image'].shape: (3, 96, 96) float32, [0,1]\n",
      "obs['agent_pos'].shape: (2,) float32, [0,512]\n",
      "action.shape:  (2,) float32, [0,512]\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Env Demo**\n",
    "#@markdown Standard Gym Env (0.21.0 API)\n",
    "\n",
    "# 0. create env object\n",
    "env = PushTImageEnv()\n",
    "\n",
    "# 1. seed env for initial state.\n",
    "# Seed 0-200 are used for the demonstration dataset.\n",
    "env.seed(1000)\n",
    "\n",
    "# 2. must reset before use\n",
    "obs, info = env.reset()\n",
    "\n",
    "# 3. 2D positional action space [0,512]\n",
    "action = env.action_space.sample()\n",
    "\n",
    "# 4. Standard gym step method\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "# prints and explains each dimension of the observation and action vectors\n",
    "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
    "    print(\"obs['image'].shape:\", obs['image'].shape, \"float32, [0,1]\")\n",
    "    print(\"obs['agent_pos'].shape:\", obs['agent_pos'].shape, \"float32, [0,512]\")\n",
    "    print(\"action.shape: \", action.shape, \"float32, [0,512]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "form",
    "id": "vHepJOFBucwg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Dataset**\n",
    "#@markdown\n",
    "#@markdown Defines `PushTImageDataset` and helper functions\n",
    "#@markdown\n",
    "#@markdown The dataset class\n",
    "#@markdown - Load data ((image, agent_pos), action) from a zarr storage\n",
    "#@markdown - Normalizes each dimension of agent_pos and action to [-1,1]\n",
    "#@markdown - Returns\n",
    "#@markdown  - All possible segments with length `pred_horizon`\n",
    "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
    "#@markdown  - key `image`: shape (obs_hoirzon, 3, 96, 96)\n",
    "#@markdown  - key `agent_pos`: shape (obs_hoirzon, 2)\n",
    "#@markdown  - key `action`: shape (pred_horizon, 2)\n",
    "\n",
    "def create_sample_indices(\n",
    "        episode_ends:np.ndarray, sequence_length:int,\n",
    "        pad_before: int=0, pad_after: int=0):\n",
    "    indices = list()\n",
    "    for i in range(len(episode_ends)):\n",
    "        start_idx = 0\n",
    "        if i > 0:\n",
    "            start_idx = episode_ends[i-1]\n",
    "        end_idx = episode_ends[i]\n",
    "        episode_length = end_idx - start_idx\n",
    "\n",
    "        min_start = -pad_before\n",
    "        max_start = episode_length - sequence_length + pad_after\n",
    "\n",
    "        # range stops one idx before end\n",
    "        for idx in range(min_start, max_start+1):\n",
    "            buffer_start_idx = max(idx, 0) + start_idx\n",
    "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
    "            start_offset = buffer_start_idx - (idx+start_idx)\n",
    "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
    "            sample_start_idx = 0 + start_offset\n",
    "            sample_end_idx = sequence_length - end_offset\n",
    "            indices.append([\n",
    "                buffer_start_idx, buffer_end_idx,\n",
    "                sample_start_idx, sample_end_idx])\n",
    "    indices = np.array(indices)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def sample_sequence(train_data, sequence_length,\n",
    "                    buffer_start_idx, buffer_end_idx,\n",
    "                    sample_start_idx, sample_end_idx):\n",
    "    result = dict()\n",
    "    for key, input_arr in train_data.items():\n",
    "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
    "        data = sample\n",
    "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
    "            data = np.zeros(\n",
    "                shape=(sequence_length,) + input_arr.shape[1:],\n",
    "                dtype=input_arr.dtype)\n",
    "            if sample_start_idx > 0:\n",
    "                data[:sample_start_idx] = sample[0]\n",
    "            if sample_end_idx < sequence_length:\n",
    "                data[sample_end_idx:] = sample[-1]\n",
    "            data[sample_start_idx:sample_end_idx] = sample\n",
    "        result[key] = data\n",
    "    return result\n",
    "\n",
    "# normalize data\n",
    "def get_data_stats(data):\n",
    "    data = data.reshape(-1,data.shape[-1])\n",
    "    stats = {\n",
    "        'min': np.min(data, axis=0),\n",
    "        'max': np.max(data, axis=0)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_data(data, stats):\n",
    "    # nomalize to [0,1]\n",
    "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
    "    # normalize to [-1, 1]\n",
    "    ndata = ndata * 2 - 1\n",
    "    return ndata\n",
    "\n",
    "def unnormalize_data(ndata, stats):\n",
    "    ndata = (ndata + 1) / 2\n",
    "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
    "    return data\n",
    "\n",
    "def get_joint_stats(dataset_paths):\n",
    "    all_agent_pos = []\n",
    "    all_actions = []\n",
    "\n",
    "    for path in dataset_paths:\n",
    "        z = zarr.open(path, 'r')\n",
    "        all_agent_pos.append(z['data']['state'][:, :2])\n",
    "        all_actions.append(z['data']['action'][:])\n",
    "\n",
    "    all_agent_pos = np.concatenate(all_agent_pos, axis=0)\n",
    "    all_actions = np.concatenate(all_actions, axis=0)\n",
    "\n",
    "    def get_data_stats(data):\n",
    "        data = data.reshape(-1, data.shape[-1])\n",
    "        return {\n",
    "            'min': np.min(data, axis=0),\n",
    "            'max': np.max(data, axis=0)\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'agent_pos': get_data_stats(all_agent_pos),\n",
    "        'action': get_data_stats(all_actions),\n",
    "    }\n",
    "    \n",
    "class PushTImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset_path: str,\n",
    "                 pred_horizon: int,\n",
    "                 obs_horizon: int,\n",
    "                 action_horizon: int,\n",
    "                 shared_stats=None):\n",
    "\n",
    "        dataset_root = zarr.open(dataset_path, 'r')\n",
    "        train_image_data = dataset_root['data']['img'][:]\n",
    "        train_image_data = np.moveaxis(train_image_data, -1, 1)\n",
    "\n",
    "        train_data = {\n",
    "            'agent_pos': dataset_root['data']['state'][:, :2],\n",
    "            'action': dataset_root['data']['action'][:]\n",
    "        }\n",
    "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
    "\n",
    "        indices = create_sample_indices(\n",
    "            episode_ends=episode_ends,\n",
    "            sequence_length=pred_horizon,\n",
    "            pad_before=obs_horizon-1,\n",
    "            pad_after=action_horizon-1\n",
    "        )\n",
    "\n",
    "        stats = dict()\n",
    "        normalized_train_data = dict()\n",
    "        for key, data in train_data.items():\n",
    "            stats[key] = shared_stats[key] if shared_stats else get_data_stats(data)\n",
    "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
    "\n",
    "        normalized_train_data['image'] = train_image_data\n",
    "\n",
    "        self.indices = indices\n",
    "        self.stats = stats\n",
    "        self.normalized_train_data = normalized_train_data\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx = self.indices[idx]\n",
    "        nsample = sample_sequence(\n",
    "            train_data=self.normalized_train_data,\n",
    "            sequence_length=self.pred_horizon,\n",
    "            buffer_start_idx=buffer_start_idx,\n",
    "            buffer_end_idx=buffer_end_idx,\n",
    "            sample_start_idx=sample_start_idx,\n",
    "            sample_end_idx=sample_end_idx\n",
    "        )\n",
    "        nsample['image'] = nsample['image'][:self.obs_horizon, :]\n",
    "        nsample['agent_pos'] = nsample['agent_pos'][:self.obs_horizon, :]\n",
    "        return nsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiPushTImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_paths, pred_horizon, obs_horizon, action_horizon):\n",
    "        self.shared_stats = get_joint_stats(dataset_paths)\n",
    "\n",
    "        self.datasets = [\n",
    "            PushTImageDataset(\n",
    "                path,\n",
    "                pred_horizon=pred_horizon,\n",
    "                obs_horizon=obs_horizon,\n",
    "                action_horizon=action_horizon,\n",
    "                shared_stats=self.shared_stats\n",
    "            )\n",
    "            for path in dataset_paths\n",
    "        ]\n",
    "        self.all_samples = sum(len(d) for d in self.datasets)\n",
    "        self.dataset_offsets = np.cumsum([0] + [len(d) for d in self.datasets[:-1]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.all_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset_idx = np.searchsorted(self.dataset_offsets, idx, side='right') - 1\n",
    "        sample_idx = idx - self.dataset_offsets[dataset_idx]\n",
    "        return self.datasets[dataset_idx][sample_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_horizon = 16\n",
    "obs_horizon = 1\n",
    "action_horizon = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  1307\n",
      "batch['image'].shape: torch.Size([32, 1, 3, 96, 96])\n",
      "batch['agent_pos'].shape: torch.Size([32, 1, 2])\n",
      "batch['action'].shape torch.Size([32, 16, 2])\n",
      "Stats:  {'agent_pos': {'min': array([2.0326886 , 0.83774143], dtype=float32), 'max': array([503.96982, 508.78946], dtype=float32)}, 'action': {'min': array([0., 0.], dtype=float32), 'max': array([511., 511.], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_paths = ['./data/range_A_base.zarr', './data/range_A_perturb.zarr', './data/range_B_base.zarr']\n",
    "# Parameters\n",
    "pred_horizon = 16\n",
    "obs_horizon = 1\n",
    "action_horizon = 8\n",
    "\n",
    "# Create Multi-Zarr dataset\n",
    "dataset = MultiPushTImageDataset(\n",
    "    dataset_paths=dataset_paths,\n",
    "    pred_horizon=pred_horizon,\n",
    "    obs_horizon=obs_horizon,\n",
    "    action_horizon=action_horizon\n",
    ")\n",
    "\n",
    "# Save training data statistics (min, max) for each dataset\n",
    "# stats = {path: ds.stats for path, ds in zip(dataset_paths, dataset.datasets)}\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "print(\"Length: \", len(dataloader))\n",
    "print(\"batch['image'].shape:\", batch['image'].shape)\n",
    "print(\"batch['agent_pos'].shape:\", batch['agent_pos'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)\n",
    "print(\"Stats: \", dataset.shared_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "id": "X-XRB_g3vsgf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Network**\n",
    "#@markdown\n",
    "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
    "#@markdown as the noies prediction network\n",
    "#@markdown\n",
    "#@markdown Components\n",
    "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
    "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
    "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
    "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
    "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
    "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
    "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class Downsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Upsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ConditionalResidualBlock1D(nn.Module):\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            cond_dim,\n",
    "            kernel_size=3,\n",
    "            n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "        ])\n",
    "\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(cond_dim, cond_channels),\n",
    "            nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "        # make sure dimensions compatible\n",
    "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        '''\n",
    "            x : [ batch_size x in_channels x horizon ]\n",
    "            cond : [ batch_size x cond_dim]\n",
    "\n",
    "            returns:\n",
    "            out : [ batch_size x out_channels x horizon ]\n",
    "        '''\n",
    "        out = self.blocks[0](x)\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(\n",
    "            embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:,0,...]\n",
    "        bias = embed[:,1,...]\n",
    "        out = scale * out + bias\n",
    "\n",
    "        out = self.blocks[1](out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalUnet1D(nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256,512,1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8\n",
    "        ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed),\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            down_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            up_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv\n",
    "\n",
    "        print(\"number of parameters: {:e}\".format(\n",
    "            sum(p.numel() for p in self.parameters()))\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "            sample: torch.Tensor,\n",
    "            timestep: Union[torch.Tensor, float, int],\n",
    "            global_cond=None):\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1,-2)\n",
    "        # (B,C,T)\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps.expand(sample.shape[0])\n",
    "\n",
    "        global_feature = self.diffusion_step_encoder(timesteps)\n",
    "\n",
    "        if global_cond is not None:\n",
    "            global_feature = torch.cat([\n",
    "                global_feature, global_cond\n",
    "            ], axis=-1)\n",
    "\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1,-2)\n",
    "        # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yXq4r744aMh1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@markdown ### **Vision Encoder**\n",
    "#@markdown\n",
    "#@markdown Defines helper functions:\n",
    "#@markdown - `get_resnet` to initialize standard ResNet vision encoder\n",
    "#@markdown - `replace_bn_with_gn` to replace all BatchNorm layers with GroupNorm\n",
    "\n",
    "def get_resnet(name:str, weights=None, **kwargs) -> nn.Module:\n",
    "    \"\"\"\n",
    "    name: resnet18, resnet34, resnet50\n",
    "    weights: \"IMAGENET1K_V1\", None\n",
    "    \"\"\"\n",
    "    # Use standard ResNet implementation from torchvision\n",
    "    func = getattr(torchvision.models, name)\n",
    "    resnet = func(weights=weights, **kwargs)\n",
    "\n",
    "    # remove the final fully connected layer\n",
    "    # for resnet18, the output dim should be 512\n",
    "    resnet.fc = torch.nn.Identity()\n",
    "    return resnet\n",
    "\n",
    "\n",
    "def replace_submodules(\n",
    "        root_module: nn.Module,\n",
    "        predicate: Callable[[nn.Module], bool],\n",
    "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Replace all submodules selected by the predicate with\n",
    "    the output of func.\n",
    "\n",
    "    predicate: Return true if the module is to be replaced.\n",
    "    func: Return new module to use.\n",
    "    \"\"\"\n",
    "    if predicate(root_module):\n",
    "        return func(root_module)\n",
    "\n",
    "    bn_list = [k.split('.') for k, m\n",
    "        in root_module.named_modules(remove_duplicate=True)\n",
    "        if predicate(m)]\n",
    "    for *parent, k in bn_list:\n",
    "        parent_module = root_module\n",
    "        if len(parent) > 0:\n",
    "            parent_module = root_module.get_submodule('.'.join(parent))\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            src_module = parent_module[int(k)]\n",
    "        else:\n",
    "            src_module = getattr(parent_module, k)\n",
    "        tgt_module = func(src_module)\n",
    "        if isinstance(parent_module, nn.Sequential):\n",
    "            parent_module[int(k)] = tgt_module\n",
    "        else:\n",
    "            setattr(parent_module, k, tgt_module)\n",
    "    # verify that all modules are replaced\n",
    "    bn_list = [k.split('.') for k, m\n",
    "        in root_module.named_modules(remove_duplicate=True)\n",
    "        if predicate(m)]\n",
    "    assert len(bn_list) == 0\n",
    "    return root_module\n",
    "\n",
    "def replace_bn_with_gn(\n",
    "    root_module: nn.Module,\n",
    "    features_per_group: int=16) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Relace all BatchNorm layers with GroupNorm.\n",
    "    \"\"\"\n",
    "    replace_submodules(\n",
    "        root_module=root_module,\n",
    "        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
    "        func=lambda x: nn.GroupNorm(\n",
    "            num_groups=x.num_features//features_per_group,\n",
    "            num_channels=x.num_features)\n",
    "    )\n",
    "    return root_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1657,
     "status": "ok",
     "timestamp": 1703131329335,
     "user": {
      "displayName": "Chi Cheng",
      "userId": "13145723388682673807"
     },
     "user_tz": 480
    },
    "id": "4APZkqh336-M",
    "outputId": "e362d582-ceac-4cdd-e866-c34858593696",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.257856e+07\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Network Demo**\n",
    "\n",
    "# construct ResNet18 encoder\n",
    "# if you have multiple camera views, use seperate encoder weights for each view.\n",
    "vision_encoder = get_resnet('resnet18')\n",
    "\n",
    "# IMPORTANT!\n",
    "# replace all BatchNorm with GroupNorm to work with EMA\n",
    "# performance will tank if you forget to do this!\n",
    "vision_encoder = replace_bn_with_gn(vision_encoder)\n",
    "\n",
    "# ResNet18 has output dim of 512\n",
    "vision_feature_dim = 512\n",
    "# agent_pos is 2 dimensional\n",
    "lowdim_obs_dim = 2\n",
    "# observation feature has 514 dims in total per step\n",
    "obs_dim = vision_feature_dim + lowdim_obs_dim\n",
    "action_dim = 2\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")\n",
    "\n",
    "# the final arch has 2 parts\n",
    "nets = nn.ModuleDict({\n",
    "    'vision_encoder': vision_encoder,\n",
    "    'noise_pred_net': noise_pred_net\n",
    "})\n",
    "\n",
    "# demo\n",
    "with torch.no_grad():\n",
    "    # example inputs\n",
    "    image = torch.zeros((1, obs_horizon,3,96,96))\n",
    "    agent_pos = torch.zeros((1, obs_horizon, 2))\n",
    "    # vision encoder\n",
    "    image_features = nets['vision_encoder'](\n",
    "        image.flatten(end_dim=1))\n",
    "    # (2,512)\n",
    "    image_features = image_features.reshape(*image.shape[:2],-1)\n",
    "    # (1,2,512)\n",
    "    obs = torch.cat([image_features, agent_pos],dim=-1)\n",
    "    # (1,2,514)\n",
    "\n",
    "    noised_action = torch.randn((1, pred_horizon, action_dim))\n",
    "    diffusion_iter = torch.zeros((1,))\n",
    "\n",
    "    # the noise prediction network\n",
    "    # takes noisy action, diffusion iteration and observation as input\n",
    "    # predicts the noise added to action\n",
    "    noise = nets['noise_pred_net'](\n",
    "        sample=noised_action,\n",
    "        timestep=diffusion_iter,\n",
    "        global_cond=obs.flatten(start_dim=1))\n",
    "\n",
    "    # illustration of removing noise\n",
    "    # the actual noise removal is performed by NoiseScheduler\n",
    "    # and is dependent on the diffusion noise schedule\n",
    "    denoised_action = noised_action - noise\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "_ = nets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CombinedMultiPushTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, perturb_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.perturb_dataset = perturb_dataset\n",
    "        self.base_len = len(base_dataset)\n",
    "        self.perturb_len = len(perturb_dataset)\n",
    "        self.length = max(self.base_len, self.perturb_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base = self.base_dataset[idx % self.base_len]\n",
    "        perturb = self.perturb_dataset[idx % self.perturb_len]\n",
    "        return {\n",
    "            'base_image': base['image'],\n",
    "            'base_agent_pos': base['agent_pos'],\n",
    "            'base_action': base['action'],\n",
    "            'perturb_image': perturb['image'],\n",
    "            'perturb_agent_pos': perturb['agent_pos'],\n",
    "            'perturb_action': perturb['action'],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_dataset = MultiPushTImageDataset(\n",
    "    dataset_paths=['data/range_A_base.zarr', 'data/range_B_base.zarr'],\n",
    "    pred_horizon=16,\n",
    "    obs_horizon=1,\n",
    "    action_horizon=8\n",
    ")\n",
    "\n",
    "perturb_dataset = MultiPushTImageDataset(\n",
    "    dataset_paths=['data/range_A_perturb.zarr'],\n",
    "    pred_horizon=16,\n",
    "    obs_horizon=1,\n",
    "    action_horizon=8\n",
    ")\n",
    "\n",
    "combined_dataset = CombinedMultiPushTDataset(base_dataset, perturb_dataset)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    combined_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import SoftDTWLossPyTorch\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "def compute_ot_loss(\n",
    "    tokens1, tokens2,\n",
    "    emb1_actions, emb2_actions,\n",
    "    supervised=True,\n",
    "    lambd=2.0,\n",
    "    gamma=1.0,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes OT loss between `tokens1` and `tokens2`, optionally with SoftDTW supervision.\n",
    "    \n",
    "    Args:\n",
    "        tokens1: Tensor of shape [B, D] (base embeddings)\n",
    "        tokens2: Tensor of shape [B, D] (perturbed embeddings)\n",
    "        emb1_actions: Tensor of shape [B, T, D] (base actions)\n",
    "        emb2_actions: Tensor of shape [B, T, D] (perturbed actions)\n",
    "        supervised: Whether to use supervised alignment\n",
    "        lambd: Weight for aligned pairs in the OT cost matrix\n",
    "        gamma: SoftDTW smoothing parameter\n",
    "        device: Device to compute on (e.g., \"cuda\" or \"cpu\")\n",
    "        \n",
    "    Returns:\n",
    "        ot_loss: Scalar OT loss\n",
    "        avg_feature_dist: Average embedding feature distance\n",
    "    \"\"\"\n",
    "    B, T, D = emb1_actions.shape\n",
    "\n",
    "    if not supervised:\n",
    "        ot_loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.1)\n",
    "        ot_loss = ot_loss_fn(tokens2, tokens1)\n",
    "        avg_feature_dist = torch.norm(tokens2 - tokens1, dim=-1).mean()\n",
    "        return ot_loss, avg_feature_dist\n",
    "\n",
    "    # --- Supervised using SoftDTW ---\n",
    "    dtw_loss_fn = SoftDTWLossPyTorch(gamma=gamma)\n",
    "    pairwise_dists = torch.zeros(B, B, device=device)\n",
    "    \n",
    "    emb2_delta = emb2_actions - emb2_actions[:, :1, :]\n",
    "    emb1_delta = emb1_actions - emb1_actions[:, :1, :]\n",
    "    emb2_expand = emb2_delta.unsqueeze(1).expand(B, B, -1, -1)\n",
    "    emb1_expand = emb1_delta.unsqueeze(0).expand(B, B, -1, -1)\n",
    "    pairwise_dists = dtw_loss_fn(\n",
    "        emb2_expand.reshape(B * B, *emb2_actions.shape[1:]),\n",
    "        emb1_expand.reshape(B * B, *emb1_actions.shape[1:])\n",
    "    ).view(B, B)\n",
    "\n",
    "    # Label alignment by min-DTW\n",
    "    labels = torch.argmin(pairwise_dists, dim=1)  # [B]\n",
    "\n",
    "    # Construct supervision weight matrix\n",
    "    W = torch.ones(B, B, device=device)\n",
    "    W[torch.arange(B), labels] = lambd\n",
    "\n",
    "    def make_custom_cost(W_matrix):\n",
    "        def cost_fn(x, y):\n",
    "            x_exp = x.unsqueeze(1)  # [B, 1, D]\n",
    "            y_exp = y.unsqueeze(0)  # [1, B, D]\n",
    "            cost = ((x_exp - y_exp) ** 2).sum(-1)  # [B, B]\n",
    "            return cost * W_matrix\n",
    "        return cost_fn\n",
    "\n",
    "    custom_cost = make_custom_cost(W)\n",
    "    ot_loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.05, truncate=18, cost=custom_cost)\n",
    "    ot_loss = ot_loss_fn(tokens2, tokens1)\n",
    "    avg_feature_dist = torch.norm(tokens2 - tokens1, dim=-1).mean()\n",
    "\n",
    "    return ot_loss, avg_feature_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d41921f5c0429c89c98675253ee9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd56f4458ed435ba607c069912f1fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    109\u001b[0m ema\u001b[38;5;241m.\u001b[39mstep(nets\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m--> 111\u001b[0m loss_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss_cpu)\n\u001b[1;32m    113\u001b[0m bc_epoch_loss\u001b[38;5;241m.\u001b[39mappend(bc_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from geomloss import SamplesLoss\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "save_dir = 'checkpoints/scaled_ot'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "ckpt_path = os.path.join(save_dir, 'ckpt.ckpt')\n",
    "start_epoch = 0\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize optimizer and EMA first\n",
    "ema = EMAModel(parameters=nets.parameters(), power=0.75)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=nets.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataloader) * num_epochs\n",
    ")\n",
    "\n",
    "# Resume if checkpoint exists\n",
    "if os.path.exists(ckpt_path):\n",
    "    print(f\" Resuming training from {ckpt_path}\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    nets.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(f\" Resumed from epoch {start_epoch}\")\n",
    "\n",
    "OT_TEMPERATURE = 0.5\n",
    "\n",
    "# Initialize lists for tracking loss\n",
    "all_loss = []\n",
    "all_bc_loss = []\n",
    "all_ot_loss = []\n",
    "\n",
    "with tqdm(range(start_epoch, num_epochs), desc='Epoch') as tglobal:\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = []\n",
    "        bc_epoch_loss = []\n",
    "        ot_epoch_loss = []\n",
    "        with tqdm(loader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # === Base domain ===\n",
    "                base_img = nbatch['base_image'][:, :obs_horizon].to(device).float() / 255.0\n",
    "                base_pos = nbatch['base_agent_pos'][:, :obs_horizon].to(device)\n",
    "                base_action = nbatch['base_action'].to(device)\n",
    "\n",
    "                # === Perturb domain ===\n",
    "                pert_img = nbatch['perturb_image'][:, :obs_horizon].to(device).float() / 255.0\n",
    "                pert_pos = nbatch['perturb_agent_pos'][:, :obs_horizon].to(device)\n",
    "                pert_action = nbatch['perturb_action'].to(device)\n",
    "\n",
    "                B = base_img.shape[0]\n",
    "\n",
    "                # ----- Encode base -----\n",
    "                base_feat = nets['vision_encoder'](base_img.flatten(0, 1))\n",
    "                base_feat = base_feat.view(B, obs_horizon, -1)\n",
    "                base_obs = torch.cat([base_feat, base_pos], dim=-1)\n",
    "                base_obs_cond = base_obs.flatten(start_dim=1)\n",
    "\n",
    "                # ----- Encode perturb -----\n",
    "                pert_feat = nets['vision_encoder'](pert_img.flatten(0, 1))\n",
    "                pert_feat = pert_feat.view(B, obs_horizon, -1)\n",
    "                pert_obs = torch.cat([pert_feat, pert_pos], dim=-1)\n",
    "                pert_obs_cond = pert_obs.flatten(start_dim=1)\n",
    "\n",
    "                # ----- OT loss -----\n",
    "                ot_loss = ot_loss, avg_feat_dist = compute_ot_loss(\n",
    "                                tokens1=pert_obs_cond,\n",
    "                                tokens2=base_obs_cond,\n",
    "                                emb1_actions=pert_action,\n",
    "                                emb2_actions=base_action,\n",
    "                                supervised=True,\n",
    "                                lambd=0.5,\n",
    "                                gamma=0.1,\n",
    "                                device=device)\n",
    "\n",
    "                # ----- Base diffusion -----\n",
    "                t_base = torch.randint(0, num_diffusion_iters, (B,), device=device).long()\n",
    "                noise_base = torch.randn_like(base_action)\n",
    "                noisy_base_action = noise_scheduler.add_noise(base_action, noise_base, t_base)\n",
    "                noise_pred_base = noise_pred_net(noisy_base_action, t_base, global_cond=base_obs_cond)\n",
    "                loss_base = nn.functional.mse_loss(noise_pred_base, noise_base)\n",
    "\n",
    "                # ----- Perturb diffusion -----\n",
    "                t_pert = torch.randint(0, num_diffusion_iters, (B,), device=device).long()\n",
    "                noise_pert = torch.randn_like(pert_action)\n",
    "                noisy_pert_action = noise_scheduler.add_noise(pert_action, noise_pert, t_pert)\n",
    "                noise_pred_pert = noise_pred_net(noisy_pert_action, t_pert, global_cond=pert_obs_cond)\n",
    "                loss_pert = nn.functional.mse_loss(noise_pred_pert, noise_pert)\n",
    "\n",
    "                # ----- Combined loss -----\n",
    "                bc_loss = loss_base + loss_pert\n",
    "                loss = bc_loss + (OT_TEMPERATURE * ot_loss)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                lr_scheduler.step()\n",
    "                ema.step(nets.parameters())\n",
    "\n",
    "                loss_cpu = loss.item()\n",
    "                epoch_loss.append(loss_cpu)\n",
    "                bc_epoch_loss.append(bc_loss.item())\n",
    "                ot_epoch_loss.append(ot_loss.item())\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "\n",
    "        tglobal.set_postfix(loss={\n",
    "            'loss': np.mean(epoch_loss),\n",
    "            'bc': np.mean(bc_epoch_loss),\n",
    "            'ot': np.mean(ot_epoch_loss)\n",
    "        })\n",
    "\n",
    "        # Append to full-epoch tracking\n",
    "        all_loss.append(np.mean(epoch_loss))\n",
    "        all_bc_loss.append(np.mean(bc_epoch_loss))\n",
    "        all_ot_loss.append(np.mean(ot_epoch_loss))\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch_idx + 1) % 10 == 0 or (epoch_idx + 1) == num_epochs:\n",
    "            ckpt_epoch_path = os.path.join(save_dir, f'ckpt_epoch_{epoch_idx+1}.ckpt')\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx + 1,\n",
    "                'model_state_dict': nets.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict(),\n",
    "                'config': {\n",
    "                    'obs_horizon': obs_horizon,\n",
    "                    'action_dim': action_dim,\n",
    "                    'obs_dim': obs_dim,\n",
    "                    'num_diffusion_iters': num_diffusion_iters\n",
    "                }\n",
    "            }, ckpt_epoch_path)\n",
    "            torch.save({\n",
    "                'epoch': epoch_idx + 1,\n",
    "                'model_state_dict': nets.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'ema_state_dict': ema.state_dict(),\n",
    "            }, ckpt_path)\n",
    "            print(f\" Saved checkpoint to {ckpt_epoch_path} and {ckpt_path}\")\n",
    "\n",
    "        # --- Plot loss curves ---\n",
    "        if (epoch_idx + 1) % 1 == 0:  # or some frequency you want\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(all_loss, label='Total Loss')\n",
    "            plt.plot(all_bc_loss, label='BC Loss')\n",
    "            plt.plot(all_ot_loss, label='OT Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training Loss Curves')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            display(plt.gcf())  # <- this shows the figure inline\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "# Apply EMA weights at end of training\n",
    "ema.copy_to(nets.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13013,
     "status": "ok",
     "timestamp": 1703131388601,
     "user": {
      "displayName": "Chi Cheng",
      "userId": "13145723388682673807"
     },
     "user_tz": 480
    },
    "id": "6F3hUbIuxGdO",
    "outputId": "36fa4685-4c4a-4ef3-a0a5-add134288f88",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded.\n"
     ]
    }
   ],
   "source": [
    "#@markdown ### **Loading Pretrained Checkpoint**\n",
    "#@markdown Set `load_pretrained = True` to load pretrained weights.\n",
    "\n",
    "load_pretrained = True\n",
    "if load_pretrained:\n",
    "  ckpt_path = \"checkpoints/cotrain_baseline/ckpt_epoch_100.ckpt\"\n",
    "  if not os.path.isfile(ckpt_path):\n",
    "      id = \"1XKpfNSlwYMGaF5CncoFaLKCDTWoLAHf1&confirm=t\"\n",
    "     # gdown.download(id=id, output=ckpt_path, quiet=False)\n",
    "\n",
    "  state_dict = torch.load(ckpt_path, map_location='cuda')[\"model_state_dict\"]\n",
    "  ema_nets = nets\n",
    "  ema_nets.load_state_dict(state_dict)\n",
    "  print('Pretrained weights loaded.')\n",
    "else:\n",
    "  print(\"Skipped pretrained weight loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 35353,
     "status": "ok",
     "timestamp": 1703131426802,
     "user": {
      "displayName": "Chi Cheng",
      "userId": "13145723388682673807"
     },
     "user_tz": 480
    },
    "id": "OyLjlNQk5nr9",
    "outputId": "4641c055-a534-48e2-cc26-0d1056a004ba",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f619aa8603f42c19cb4587dfc88832a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval PushTImageEnv:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "### In-domain\n",
    "# limit enviornment interaction to 200 steps before termination\n",
    "\n",
    "shared_stats = base_dataset.shared_stats\n",
    "\n",
    "max_steps = 200\n",
    "env = PushTImageEnv()\n",
    "# use a seed >200 to avoid initial states seen in the training dataset\n",
    "env.seed(10000)\n",
    "\n",
    "# get first observation\n",
    "obs, info = env.reset()\n",
    "\n",
    "# keep a queue of last 2 steps of observations\n",
    "obs_deque = collections.deque(\n",
    "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
    "# save visualization and rewards\n",
    "imgs = [env.render(mode='rgb_array')]\n",
    "rewards = list()\n",
    "done = False\n",
    "step_idx = 0\n",
    "\n",
    "stats = shared_stats\n",
    "with tqdm(total=max_steps, desc=\"Eval PushTImageEnv\") as pbar:\n",
    "    while not done:\n",
    "        B = 1\n",
    "        # stack the last obs_horizon number of observations\n",
    "        images = np.stack([x['image'] for x in obs_deque])\n",
    "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
    "\n",
    "        # normalize observation\n",
    "        nagent_poses = normalize_data(agent_poses, stats=stats['agent_pos'])\n",
    "        # images are already normalized to [0,1]\n",
    "        nimages = images\n",
    "\n",
    "        # device transfer\n",
    "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
    "\n",
    "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
    "        # (2,2)\n",
    "\n",
    "        # infer action\n",
    "        with torch.no_grad():\n",
    "            # get image features\n",
    "            image_features = ema_nets['vision_encoder'](nimages)\n",
    "            # (2,512)\n",
    "\n",
    "            # concat with low-dim observations\n",
    "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
    "\n",
    "            # reshape observation to (B,obs_horizon*obs_dim)\n",
    "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
    "\n",
    "            # initialize action from Guassian noise\n",
    "            noisy_action = torch.randn(\n",
    "                (B, pred_horizon, action_dim), device=device)\n",
    "            naction = noisy_action\n",
    "\n",
    "            # init scheduler\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                # predict noise\n",
    "                noise_pred = ema_nets['noise_pred_net'](\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                # inverse diffusion step (remove noise)\n",
    "                naction = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "\n",
    "        # unnormalize action\n",
    "        naction = naction.detach().to('cpu').numpy()\n",
    "        # (B, pred_horizon, action_dim)\n",
    "        naction = naction[0]\n",
    "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
    "\n",
    "        # only take action_horizon number of actions\n",
    "        start = obs_horizon - 1\n",
    "        end = start + action_horizon\n",
    "        action = action_pred[start:end,:]\n",
    "        # (action_horizon, action_dim)\n",
    "\n",
    "        # execute action_horizon number of steps\n",
    "        # without replanning\n",
    "        for i in range(len(action)):\n",
    "            # stepping env\n",
    "            obs, reward, done, _, info = env.step(action[i])\n",
    "            # save observations\n",
    "            obs_deque.append(obs)\n",
    "            # and reward/vis\n",
    "            rewards.append(reward)\n",
    "            imgs.append(env.render(mode='rgb_array'))\n",
    "\n",
    "            # update progress bar\n",
    "            step_idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(reward=reward)\n",
    "            if step_idx > max_steps:\n",
    "                done = True\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "# print out the maximum target coverage\n",
    "print('Score: ', max(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc1d0106f44437c80b9586e7829e4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating random seeds:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved per-seed scores to per_seed_scores.json\n",
      " Mean max reward: 0.7226\n",
      " Variance: 0.0932\n",
      " Success Rate ( 0.9): 49.00%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "# --- Config ---\n",
    "num_trials = 100\n",
    "seed_range = (101, 9999)\n",
    "max_steps = 200\n",
    "success_threshold = 0.9\n",
    "log_file = \"per_seed_scores.json\"\n",
    "\n",
    "# --- Fix global randomness ---\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Sample random but reproducible set of seeds\n",
    "eval_seeds = random.sample(range(*seed_range), num_trials)\n",
    "\n",
    "# Get shared stats from dataset\n",
    "shared_stats = base_dataset.shared_stats\n",
    "\n",
    "# --- Storage for per-seed results ---\n",
    "per_seed_scores = {}\n",
    "\n",
    "for seed in tqdm(eval_seeds, desc=\"Evaluating random seeds\"):\n",
    "    env = PushTImageEnv()\n",
    "    env.seed(seed)\n",
    "    obs, info = env.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "    rewards = []\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "\n",
    "    while not done:\n",
    "        B = 1\n",
    "        images = np.stack([x['image'] for x in obs_deque])\n",
    "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
    "\n",
    "        nagent_poses = normalize_data(agent_poses, stats=shared_stats['agent_pos'])\n",
    "        nimages = images\n",
    "\n",
    "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
    "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = ema_nets['vision_encoder'](nimages)\n",
    "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
    "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
    "\n",
    "            noisy_action = torch.randn((B, pred_horizon, action_dim), device=device)\n",
    "            naction = noisy_action\n",
    "\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                noise_pred = ema_nets['noise_pred_net'](\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "                naction = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "\n",
    "        naction = naction[0].cpu().numpy()\n",
    "        action_pred = unnormalize_data(naction, stats=shared_stats['action'])\n",
    "        action = action_pred[obs_horizon - 1: obs_horizon - 1 + action_horizon]\n",
    "\n",
    "        for a in action:\n",
    "            obs, reward, done, _, info = env.step(a)\n",
    "            obs_deque.append(obs)\n",
    "            rewards.append(reward)\n",
    "            step_idx += 1\n",
    "            if step_idx >= max_steps or done:\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "    per_seed_scores[seed] = float(max(rewards))\n",
    "\n",
    "# --- Save to JSON file ---\n",
    "with open(log_file, 'w') as f:\n",
    "    json.dump(per_seed_scores, f, indent=2)\n",
    "print(f\" Saved per-seed scores to {log_file}\")\n",
    "\n",
    "# --- Summary stats ---\n",
    "all_scores = np.array(list(per_seed_scores.values()))\n",
    "mean_reward = np.mean(all_scores)\n",
    "var_reward = np.var(all_scores)\n",
    "success_rate = np.mean(all_scores >= success_threshold)\n",
    "\n",
    "print(f\" Mean max reward: {mean_reward:.4f}\")\n",
    "print(f\" Variance: {var_reward:.4f}\")\n",
    "print(f\" Success Rate ( {success_threshold}): {success_rate * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=640 controls>\n",
       "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import tempfile\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Save imgs (a list of HWC RGB arrays) as mp4\n",
    "with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as f:\n",
    "    video_path = f.name\n",
    "    writer = imageio.get_writer(video_path, fps=10, format='ffmpeg')\n",
    "    for frame in imgs:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "\n",
    "# Display the video inline in a notebook\n",
    "with open(video_path, \"rb\") as f:\n",
    "    mp4 = f.read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=640 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be95c7ab875b4a2aa143643114bce2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval PushTImageEnv:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6168653822669348\n"
     ]
    }
   ],
   "source": [
    "### Out of domain\n",
    "# limit enviornment interaction to 200 steps before termination\n",
    "\n",
    "shared_stats = perturb_dataset.shared_stats\n",
    "\n",
    "max_steps = 200\n",
    "env = PushTImageEnv2()\n",
    "# use a seed >200 to avoid initial states seen in the training dataset\n",
    "env.seed(10000)\n",
    "\n",
    "# get first observation\n",
    "obs, info = env.reset()\n",
    "\n",
    "# keep a queue of last 2 steps of observations\n",
    "obs_deque = collections.deque(\n",
    "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
    "# save visualization and rewards\n",
    "imgs = [env.render(mode='rgb_array')]\n",
    "rewards = list()\n",
    "done = False\n",
    "step_idx = 0\n",
    "print\n",
    "stats = shared_stats\n",
    "with tqdm(total=max_steps, desc=\"Eval PushTImageEnv\") as pbar:\n",
    "    while not done:\n",
    "        B = 1\n",
    "        # stack the last obs_horizon number of observations\n",
    "        images = np.stack([x['image'] for x in obs_deque])\n",
    "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
    "\n",
    "        # normalize observation\n",
    "        nagent_poses = normalize_data(agent_poses, stats=stats['agent_pos'])\n",
    "        # images are already normalized to [0,1]\n",
    "        nimages = images\n",
    "\n",
    "        # device transfer\n",
    "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
    "\n",
    "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
    "        # (2,2)\n",
    "\n",
    "        # infer action\n",
    "        with torch.no_grad():\n",
    "            # get image features\n",
    "            image_features = ema_nets['vision_encoder'](nimages)\n",
    "            # (2,512)\n",
    "\n",
    "            # concat with low-dim observations\n",
    "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
    "\n",
    "            # reshape observation to (B,obs_horizon*obs_dim)\n",
    "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
    "\n",
    "            # initialize action from Guassian noise\n",
    "            noisy_action = torch.randn(\n",
    "                (B, pred_horizon, action_dim), device=device)\n",
    "            naction = noisy_action\n",
    "\n",
    "            # init scheduler\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                # predict noise\n",
    "                noise_pred = ema_nets['noise_pred_net'](\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                # inverse diffusion step (remove noise)\n",
    "                naction = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "\n",
    "        # unnormalize action\n",
    "        naction = naction.detach().to('cpu').numpy()\n",
    "        # (B, pred_horizon, action_dim)\n",
    "        naction = naction[0]\n",
    "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
    "\n",
    "        # only take action_horizon number of actions\n",
    "        start = obs_horizon - 1\n",
    "        end = start + action_horizon\n",
    "        action = action_pred[start:end,:]\n",
    "        # (action_horizon, action_dim)\n",
    "\n",
    "        # execute action_horizon number of steps\n",
    "        # without replanning\n",
    "        for i in range(len(action)):\n",
    "            # stepping env\n",
    "            obs, reward, done, _, info = env.step(action[i])\n",
    "            # save observations\n",
    "            obs_deque.append(obs)\n",
    "            # and reward/vis\n",
    "            rewards.append(reward)\n",
    "            imgs.append(env.render(mode='rgb_array'))\n",
    "\n",
    "            # update progress bar\n",
    "            step_idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(reward=reward)\n",
    "            if step_idx > max_steps:\n",
    "                done = True\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "# print out the maximum target coverage\n",
    "print('Score: ', max(rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9208320cba0940c08666e15041e38a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating OOD seeds:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved per-seed OOD scores to ood_per_seed_scores.json\n",
      " OOD Mean max reward: 0.6307\n",
      " OOD Variance: 0.0635\n",
      " OOD Success Rate ( 0.9): 24.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Config ---\n",
    "num_trials = 100\n",
    "seed_range = (101, 9999)\n",
    "max_steps = 200\n",
    "success_threshold = 0.9\n",
    "log_file = \"ood_per_seed_scores.json\"\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Sample random seeds\n",
    "eval_seeds = random.sample(range(*seed_range), num_trials)\n",
    "\n",
    "# Shared normalization stats from perturb dataset\n",
    "shared_stats = perturb_dataset.shared_stats\n",
    "\n",
    "# Track scores\n",
    "per_seed_scores = {}\n",
    "\n",
    "# Evaluation loop\n",
    "for seed in tqdm(eval_seeds, desc=\"Evaluating OOD seeds\"):\n",
    "    env = PushTImageEnv2()\n",
    "    env.seed(seed)\n",
    "    obs, info = env.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "    rewards = []\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "\n",
    "    while not done:\n",
    "        B = 1\n",
    "        images = np.stack([x['image'] for x in obs_deque])\n",
    "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
    "\n",
    "        nagent_poses = normalize_data(agent_poses, stats=shared_stats['agent_pos'])\n",
    "        nimages = images\n",
    "\n",
    "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
    "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = ema_nets['vision_encoder'](nimages)\n",
    "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
    "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
    "\n",
    "            noisy_action = torch.randn((B, pred_horizon, action_dim), device=device)\n",
    "            naction = noisy_action\n",
    "\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                noise_pred = ema_nets['noise_pred_net'](\n",
    "                    sample=naction,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "                naction = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=naction\n",
    "                ).prev_sample\n",
    "\n",
    "        naction = naction[0].cpu().numpy()\n",
    "        action_pred = unnormalize_data(naction, stats=shared_stats['action'])\n",
    "        action = action_pred[obs_horizon - 1: obs_horizon - 1 + action_horizon]\n",
    "\n",
    "        for a in action:\n",
    "            obs, reward, done, _, info = env.step(a)\n",
    "            obs_deque.append(obs)\n",
    "            rewards.append(reward)\n",
    "            step_idx += 1\n",
    "            if step_idx >= max_steps or done:\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "    per_seed_scores[seed] = float(max(rewards))\n",
    "\n",
    "# Save scores to file\n",
    "with open(log_file, 'w') as f:\n",
    "    json.dump(per_seed_scores, f, indent=2)\n",
    "print(f\" Saved per-seed OOD scores to {log_file}\")\n",
    "\n",
    "# Final stats\n",
    "all_scores = np.array(list(per_seed_scores.values()))\n",
    "mean_reward = np.mean(all_scores)\n",
    "var_reward = np.var(all_scores)\n",
    "success_rate = np.mean(all_scores >= success_threshold)\n",
    "\n",
    "print(f\" OOD Mean max reward: {mean_reward:.4f}\")\n",
    "print(f\" OOD Variance: {var_reward:.4f}\")\n",
    "print(f\" OOD Success Rate ( {success_threshold}): {success_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=640 controls>\n",
       "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import tempfile\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Save imgs (a list of HWC RGB arrays) as mp4\n",
    "with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as f:\n",
    "    video_path = f.name\n",
    "    writer = imageio.get_writer(video_path, fps=10, format='ffmpeg')\n",
    "    for frame in imgs:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "\n",
    "# Display the video inline in a notebook\n",
    "with open(video_path, \"rb\") as f:\n",
    "    mp4 = f.read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "HTML(f\"\"\"\n",
    "<video width=640 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "18GIHeOQ5DyjMN8iIRZL2EKZ0745NLIpg",
     "timestamp": 1743615951827
    }
   ]
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7041446,
     "sourceId": 11265175,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7042841,
     "sourceId": 11266998,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7043649,
     "sourceId": 11268141,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "diffp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0873a2dee0e44b0fb3e8445d94c27171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fd765bcd2a34db49a02839ba1c4f518",
      "placeholder": "",
      "style": "IPY_MODEL_d9054c34284045eda3546a21bb5fafc3",
      "value": "Epoch:   2%"
     }
    },
    "09152dbe3c8543aa809aa592afdc53f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47b6383ed3b64b7e8c7e66d0e7a468d9",
      "placeholder": "",
      "style": "IPY_MODEL_1cdde5afac8041bf9b75e0e80bd80630",
      "value": " 2/100 [03:14&lt;2:38:57, 97.32s/it, loss=0.0192]"
     }
    },
    "12ef3c026774405cb91faf18d7fd8afa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb23edb22d624aee9fd55ab05e2a517e",
      "placeholder": "",
      "style": "IPY_MODEL_a073d659b0f347c9b30c343430d7f6aa",
      "value": " 379/379 [01:37&lt;00:00,  4.40it/s, loss=0.0185]"
     }
    },
    "16b5928585984a1b81b809717f125489": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1faac530b70b41a58a8c9c0cf44af69c",
      "placeholder": "",
      "style": "IPY_MODEL_7cfefcf49a9a426da4e9203ec4debe38",
      "value": " 379/379 [01:37&lt;00:00,  4.57it/s, loss=0.0103]"
     }
    },
    "182afbf676cd4c0982b90890bbdbeeef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "185ce2207cec4ae1a6ffdecadae23894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b96a78d8b8542eb830e3c446a0dcf42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cdde5afac8041bf9b75e0e80bd80630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d0a57ed8e914d31bcc1c36a56451df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cc800669dfd45a784864dd4a3881daa",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95dc6c44f97e4e8882a3657bd2fd66fb",
      "value": 200
     }
    },
    "1faac530b70b41a58a8c9c0cf44af69c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c31ffecd0494e2a8d0a8cefbea5df8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d4a78f691ec4555bf179e5ef5d828ac",
      "placeholder": "",
      "style": "IPY_MODEL_1b96a78d8b8542eb830e3c446a0dcf42",
      "value": "Eval PushTImageEnv: "
     }
    },
    "333b5148e59e47f3998a5cf5df531baf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "353cb60a2a73417b81ccbb5e52480ed3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c0a27b6addb4c6a977824995548fe90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e503eeff5d94f0e9dc8a3d31190c6a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "410476fa4ac14dd2b78377f4d779402f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a92fc95c6a3d496997da90c87e24ba01",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a98272475d940b1b98438c4d02dcc05",
      "value": 2
     }
    },
    "44c486fa8c4241f4a1a245f4e24da769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c0a27b6addb4c6a977824995548fe90",
      "max": 379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d14f2c65ef9348348250af2df0f32963",
      "value": 379
     }
    },
    "479d2f35498b4fbea77057f3f26fd287": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c25264289e3411db29f6f8db936b00f",
      "max": 379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0ff8cd1b00544caa12cbd809524dd15",
      "value": 379
     }
    },
    "47b6383ed3b64b7e8c7e66d0e7a468d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4abc5a8b257240b99535a6abe5e00ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cc800669dfd45a784864dd4a3881daa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5124950790874225b5cca7556f122f9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c1c61cd14fb4aa8b335684fbf652a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69f323a406004822bf1a0bfd79767c9a",
      "max": 379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88a8f5924a1e4a86805e314dd90c17be",
      "value": 11
     }
    },
    "5d4a78f691ec4555bf179e5ef5d828ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f96241543b441fcb13c16d4ca476405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6bbb6ce052045ca895b526c620d8847",
       "IPY_MODEL_5c1c61cd14fb4aa8b335684fbf652a29",
       "IPY_MODEL_a5a2bc5dc0b54a4796e574308bb6c4bc"
      ],
      "layout": "IPY_MODEL_febe66177c604395a78be993eeff7c6d"
     }
    },
    "69f323a406004822bf1a0bfd79767c9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c25264289e3411db29f6f8db936b00f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de3445a866442aa9cc7d855cb0d0740": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70b4b657d68648d9be98c099d061cd5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c0237e38cfd4143aa423dea26637965",
       "IPY_MODEL_44c486fa8c4241f4a1a245f4e24da769",
       "IPY_MODEL_12ef3c026774405cb91faf18d7fd8afa"
      ],
      "layout": "IPY_MODEL_99c0577d549c4dd4a61d9ec0cf6254d5"
     }
    },
    "7508fbad995648a39d2a55953d000786": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9009dc5a656c4befbf513f2574df5a7d",
       "IPY_MODEL_479d2f35498b4fbea77057f3f26fd287",
       "IPY_MODEL_16b5928585984a1b81b809717f125489"
      ],
      "layout": "IPY_MODEL_9d436c7ee90349a5966f025d095dd0cc"
     }
    },
    "7cfefcf49a9a426da4e9203ec4debe38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fd765bcd2a34db49a02839ba1c4f518": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a8f5924a1e4a86805e314dd90c17be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c0237e38cfd4143aa423dea26637965": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5124950790874225b5cca7556f122f9a",
      "placeholder": "",
      "style": "IPY_MODEL_f609505b750747dcaff8a950131743e9",
      "value": "Batch: 100%"
     }
    },
    "9009dc5a656c4befbf513f2574df5a7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e503eeff5d94f0e9dc8a3d31190c6a2",
      "placeholder": "",
      "style": "IPY_MODEL_4abc5a8b257240b99535a6abe5e00ef6",
      "value": "Batch: 100%"
     }
    },
    "95dc6c44f97e4e8882a3657bd2fd66fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99c0577d549c4dd4a61d9ec0cf6254d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "9a98272475d940b1b98438c4d02dcc05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9ada44d21f234712ac5df797c730495a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d436c7ee90349a5966f025d095dd0cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "a073d659b0f347c9b30c343430d7f6aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ff8cd1b00544caa12cbd809524dd15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5a2bc5dc0b54a4796e574308bb6c4bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ada44d21f234712ac5df797c730495a",
      "placeholder": "",
      "style": "IPY_MODEL_c777ac64366c40ea8a1f63408879c2ab",
      "value": " 11/379 [00:03&lt;01:34,  3.91it/s, loss=0.0256]"
     }
    },
    "a92fc95c6a3d496997da90c87e24ba01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0a9f64f47d34769a47e165291d2c550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c31ffecd0494e2a8d0a8cefbea5df8a",
       "IPY_MODEL_1d0a57ed8e914d31bcc1c36a56451df7",
       "IPY_MODEL_e1bb86eb510b47d9ac2311926455bf1f"
      ],
      "layout": "IPY_MODEL_182afbf676cd4c0982b90890bbdbeeef"
     }
    },
    "b34bf5a5d603446fb453bbed31c4469c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0873a2dee0e44b0fb3e8445d94c27171",
       "IPY_MODEL_410476fa4ac14dd2b78377f4d779402f",
       "IPY_MODEL_09152dbe3c8543aa809aa592afdc53f1"
      ],
      "layout": "IPY_MODEL_e2a91fa6d1514913892c0def2e2ecf78"
     }
    },
    "c777ac64366c40ea8a1f63408879c2ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14f2c65ef9348348250af2df0f32963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9054c34284045eda3546a21bb5fafc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1bb86eb510b47d9ac2311926455bf1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_333b5148e59e47f3998a5cf5df531baf",
      "placeholder": "",
      "style": "IPY_MODEL_185ce2207cec4ae1a6ffdecadae23894",
      "value": " 201/? [00:34&lt;00:00,  6.11it/s, reward=0.828]"
     }
    },
    "e2a91fa6d1514913892c0def2e2ecf78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bbb6ce052045ca895b526c620d8847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6de3445a866442aa9cc7d855cb0d0740",
      "placeholder": "",
      "style": "IPY_MODEL_353cb60a2a73417b81ccbb5e52480ed3",
      "value": "Batch:   3%"
     }
    },
    "eb23edb22d624aee9fd55ab05e2a517e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f609505b750747dcaff8a950131743e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "febe66177c604395a78be993eeff7c6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
